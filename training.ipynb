{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "source": [
    "# Deep Learning with PyTorch\n",
    "\n",
    "This is notebook for excersises with [PyTorch](https://pytorch.ord) framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import halper\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "# Define activation functions\n",
    "def sigmoid(x):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    \"\"\"TanH (Hyperbolic Tangent Function) activation function\"\"\"\n",
    "    return torch.tanh(x)\n",
    "\n",
    "relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "source": [
    "## Single Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "torch.manual_seed(7)\n",
    "\n",
    "# Init features, weights, bias\n",
    "features = torch.randn(1, 5)\n",
    "weights = torch.randn_like(features)\n",
    "bias = torch.randn(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
      "Weights:  tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]])\n",
      "Bias:  tensor([[0.3177]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Features: \", features)\n",
    "print(\"Weights: \", weights)\n",
    "print(\"Bias: \", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1595]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate output\n",
    "y = sigmoid(torch.sum(features * weights) + bias)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1595]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate output using matrix multiplication\n",
    "y = sigmoid(torch.mm(features, weights.view(5,1)) + bias)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "source": [
    "## Stack neurons to layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structure\n",
    "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
    "n_hidden = 2                    # Number of hidden units \n",
    "n_output = 1                    # Number of output units\n",
    "\n",
    "# Weights for inputs to hidden layer\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "# Weights for hidden layer to output layer\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "# Bias terms for hidden and output layers\n",
    "B1 = torch.randn(1, n_hidden)\n",
    "B2 = torch.randn(1, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
      "Input:  5\n",
      "W1:  tensor([[ 0.3697, -0.5606],\n",
      "        [ 0.2646,  0.7064],\n",
      "        [-0.8986, -0.0961],\n",
      "        [-1.2592,  0.0418],\n",
      "        [ 0.1011,  0.1490]])\n",
      "W2:  tensor([[-0.9955],\n",
      "        [-1.9522]])\n",
      "B1:  tensor([[0.4783, 1.0590]])\n",
      "B2:  tensor([[0.9997]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Features: \", features)\n",
    "print(\"Input: \", features.shape[1])\n",
    "print(\"W1: \", W1)\n",
    "print(\"W2: \", W2)\n",
    "print(\"B1: \", B1)\n",
    "print(\"B2: \", B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0201]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = relu(torch.mm(features, W1) + B1)\n",
    "y = sigmoid(torch.mm(h, W2) + B2)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "source": [
    "## Network for text recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11937fc88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 253.0,
       "height": 250.0
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "# Define the structure\n",
    "n_inp = 784     # Number of input units\n",
    "n_hid = 256    # Number of hidden units \n",
    "n_out = 10     # Number of output units\n",
    "\n",
    "inputs = images.view(images.shape[0], -1)\n",
    "\n",
    "# Weights for inputs to hidden layer\n",
    "w1 = torch.randn(n_inp, n_hid)\n",
    "w2 = torch.randn(n_hid, n_out)\n",
    "\n",
    "# Bias terms for hidden and output layers\n",
    "b1 = torch.randn(1, n_hid)\n",
    "b2 = torch.randn(1, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.4434,   7.8544,  -4.3700, -10.8325, -22.0773,   8.8793,  -1.1883,\n",
       "          14.2450,  14.4344,  12.9310],\n",
       "        [  2.6226,  -4.3502,  -7.6140,  -7.6205, -18.5064,  22.0171,   5.9612,\n",
       "          12.5862,  12.4638,   6.3309],\n",
       "        [  7.6701,  -1.8777,  -9.6569,  -6.7564, -22.7910,  15.1550,   0.5149,\n",
       "          19.5564,  11.1055,   8.9383],\n",
       "        [  6.1556,  -3.3284, -12.3642, -12.5019, -21.2607,  10.0948,   6.7729,\n",
       "          12.4125,  18.1837,  18.8285],\n",
       "        [ 10.8766,   2.7531,  -2.2908,   0.8693, -24.0313,  12.2843,  -0.3357,\n",
       "          19.6347,   8.1872,   9.5545],\n",
       "        [  7.6735,  -0.9138,  -2.9558,  -7.9115, -18.5644,  13.6824,   5.5018,\n",
       "          17.8240,  17.2933,   8.1571],\n",
       "        [ 14.0969,  -1.9209,  -1.0299,  -3.6734, -21.6592,  18.3034,   4.9690,\n",
       "          13.9612,  19.1078,   9.1441],\n",
       "        [  6.4749,  -0.2957,  -7.3822,  -4.8512, -16.3132,  23.4433,   2.1114,\n",
       "          20.0666,  14.1122,  14.3901],\n",
       "        [  1.8112,  -3.5454,  -7.5679,   4.5000, -19.0746,  12.3558,   7.9636,\n",
       "          19.1321,  14.2216,  14.1138],\n",
       "        [  6.3165,   3.2822,  -7.4319,  -0.8370, -23.3747,  19.5724,   6.8280,\n",
       "           8.1430,  14.8061,  18.0995],\n",
       "        [  6.7968,  -4.1188, -14.8564,  -6.8827, -24.9220,  18.4598,   8.3374,\n",
       "          13.9214,   8.7120,  10.3273],\n",
       "        [ 16.5363,  -5.0883,   1.9863,  -2.2301, -16.5997,  22.8885,  -7.2279,\n",
       "          14.0137,  19.4634,   5.2460],\n",
       "        [  5.8110,  -1.7488, -11.7882,   3.6666, -15.9500,  15.1870,  17.7002,\n",
       "           7.9750,  27.4017,  12.8958],\n",
       "        [ 14.0599,  -0.0345, -17.1526,   0.3268, -23.8505,  15.3970,  11.2123,\n",
       "          10.2410,  11.1095,   9.2399],\n",
       "        [ 15.2040,   4.3281, -11.5042,  -8.3452, -23.2991,   5.9945,  11.0316,\n",
       "          14.2840,  14.8724,  -2.2309],\n",
       "        [ 10.7341,  -4.6859,   2.0228,  -4.5115, -22.7180,  13.2150,  17.7706,\n",
       "           4.5659,  13.4127,  16.3220],\n",
       "        [  6.8630,   4.3182, -11.4153,   5.9329, -11.0749,   4.8841,  -5.0811,\n",
       "          11.6789,  10.1510,   6.1287],\n",
       "        [ 14.3777,   3.1500,  -3.6127,  -1.9660, -15.8484,   8.0055,  11.0879,\n",
       "           8.3249,   9.1888,   5.1993],\n",
       "        [ 14.3893,  -1.6897,  -6.3142,  -2.0479, -19.6857,  15.0383,   5.0311,\n",
       "          19.2241,  11.2142,   5.8737],\n",
       "        [  8.0215,   7.4690,  -3.2601,  -0.3696, -16.2640,  19.2195,   8.6289,\n",
       "          11.0617,   9.9671,   6.7104],\n",
       "        [  8.0331,   2.0753,  -8.7374,   2.0855, -11.4650,  18.1383,   9.9360,\n",
       "          -0.2544,  23.5627,  10.7189],\n",
       "        [  6.3210,  -2.1557,   3.0944,  -2.8219, -19.2627,  15.8222,  11.2623,\n",
       "           4.2866,  14.6178,  11.9291],\n",
       "        [  6.3089,  -3.6404,  -6.4454,  -1.1160, -24.4271,   8.5017,   2.2656,\n",
       "          18.1531,  10.1848,  16.7956],\n",
       "        [  1.1083,  -6.8548,  -0.8636,   0.8319, -16.5184,  14.1518,  13.7807,\n",
       "           9.3248,  12.2072,  10.6773],\n",
       "        [ -2.8909,  -8.9953,  -6.4956,  -7.7020, -11.0452,  22.4623,   5.0047,\n",
       "          15.0848,  12.3530,  19.9440],\n",
       "        [  7.2695,   2.0129,  -8.1227,  -0.4475, -13.5162,  20.1290,  11.7874,\n",
       "           6.2528,   7.5812,   8.8727],\n",
       "        [  1.9785,  -3.1094,  -5.9247,  -5.8121, -23.4985,   4.8175,   6.4663,\n",
       "          13.7735,  18.8654,  11.1539],\n",
       "        [ 10.6051,  -0.6610, -11.5640,   6.9500, -15.8310,   9.0664,   4.8769,\n",
       "          18.1729,  10.6699,   3.5696],\n",
       "        [  9.9375,   1.7193,  -7.0257,  -5.6293, -20.4073,  22.5238,  10.9842,\n",
       "          18.5627,  12.6015,   3.7259],\n",
       "        [  5.9662,  -3.9751,  -7.7362,  -4.9470, -21.8478,  12.0333,   7.7386,\n",
       "          16.0143,  14.8034,  12.2954],\n",
       "        [ 15.6726,  -7.9276,  -8.3846, -10.2044, -26.4581,  31.8759,   1.2094,\n",
       "          18.3333,  10.5944,   4.2921],\n",
       "        [ -0.6463,  -4.5133,  -5.5436,  -4.9577,  -5.6118,  12.3023,   4.9711,\n",
       "           4.8373,  14.7141,   6.7079],\n",
       "        [  9.1544,  -7.2021,  -3.0567,   1.6364, -22.0049,   6.9725,  12.8317,\n",
       "          19.9849,  20.1835,  15.3304],\n",
       "        [  4.3218,  -6.6450,   0.8554,  -7.0848, -20.2964,  14.4376,   8.2643,\n",
       "           9.9536,  14.2655,   4.7049],\n",
       "        [  6.9860,   1.8277,  -6.7737,  -7.4129, -11.6095,  18.6291,   5.3589,\n",
       "          18.5792,  21.4177,  15.0252],\n",
       "        [  5.8269,  -4.7340,  -4.2858,   1.7923, -18.1357,  16.2733,  14.4104,\n",
       "          12.9049,  21.0312,   9.8164],\n",
       "        [  6.0634,  -4.3895,   0.7216,  -3.2403, -17.0491,  13.5324,   7.1569,\n",
       "           9.9983,  14.9805,  14.2976],\n",
       "        [  3.2633,  -0.1866, -17.8098,   4.3688,  -8.1645,   2.1557,   4.8733,\n",
       "          14.9965,  15.6867,   7.4936],\n",
       "        [  2.0130,   3.6677,  -4.3592, -16.7159, -17.7851,  15.9915,   2.7271,\n",
       "           2.1974,  11.0012,   5.3590],\n",
       "        [ 11.4499,   0.0802, -10.9521,  -5.3272, -26.2642,  10.5788,  11.2662,\n",
       "          18.1740,  23.6310,   9.0716],\n",
       "        [  6.7346,  -3.9903,  -6.6494,  -2.1007, -17.1552,  20.5974,   2.9678,\n",
       "           9.7306,  17.9398,   4.7441],\n",
       "        [  4.0407,   0.1611,   0.2224,  -4.8055, -10.9318,  13.1492,   6.7091,\n",
       "          15.6996,  14.1318,   3.4032],\n",
       "        [  5.6413,  -5.7317,  -0.7426,  -0.9560, -11.4772,  25.6899,  -5.9072,\n",
       "           3.3817,   9.1334,   9.5548],\n",
       "        [ 10.7509,  -1.7622,  -0.7693,   0.0783, -14.6658,  18.8387,   6.9897,\n",
       "          18.0134,  10.2028,   8.4599],\n",
       "        [  7.1504,  -5.6056,  -3.7252,  -0.1592, -16.4076,   8.4351,  11.4983,\n",
       "          15.8026,  14.6723,   9.1623],\n",
       "        [ 12.9734,   3.8591, -13.3397,  -3.5540, -24.8155,  14.6229,   4.8981,\n",
       "          17.6094,   6.4113,   5.5486],\n",
       "        [  9.4391,  -8.5605, -13.3620,   2.5617, -19.4536,  15.6440,   8.1359,\n",
       "          22.2141,  24.7331,  12.3937],\n",
       "        [  1.0767,  -0.7900,  -7.8163,   2.0404, -17.3817,   2.0887,  17.0972,\n",
       "          22.2525,  15.6578,   8.2792],\n",
       "        [  7.4446,   1.9962,  -7.2146,  -6.7012, -13.1316,  15.0311,   8.4595,\n",
       "          13.3501,  19.9224,  12.9130],\n",
       "        [  0.8725,  -6.1026,  -7.8901,  -9.3223, -14.4718,  13.3960,   0.2334,\n",
       "          15.6899,  12.5649,  13.6564],\n",
       "        [  4.3718,   4.1139,   1.9605,  -9.0111, -14.8662,  15.5318,   7.3222,\n",
       "          13.9730,  13.5493,   5.2054],\n",
       "        [  5.6396,  -3.2140,  -5.5561,  -4.0035, -25.0710,   6.5575,   6.3440,\n",
       "          18.0327,  16.1766,  12.0950],\n",
       "        [  4.2103,  -2.1068, -10.8527,  -2.7740, -22.1471,  13.0767,   5.7934,\n",
       "          12.0377,  14.0649,  11.0882],\n",
       "        [ -4.8331,  -3.1234,  -2.7034,   9.8077, -10.3076,   6.4247,  13.2903,\n",
       "          15.9906,  17.6943,  15.5206],\n",
       "        [ 10.1121,   6.5126,  -4.7367,   0.1917, -11.1832,  19.3624,   7.2995,\n",
       "          17.3965,  11.5718,  13.8888],\n",
       "        [  7.9104,   1.6078,  -9.4582,  -3.5243, -21.4228,  15.6719,   4.9522,\n",
       "          19.2469,  27.0160,  -1.1648],\n",
       "        [ 18.0134,  -3.7569,   0.0495,  -8.3153, -26.2137,  17.2767,   5.9220,\n",
       "          11.5460,   9.3026,   1.4533],\n",
       "        [  6.5848,   6.8361,  -7.9790, -14.3125, -16.1410,  15.7137,  -4.4210,\n",
       "          15.3505,   4.1004,  12.6975],\n",
       "        [  7.7909,   3.2678,  -6.8859,  -1.8810, -11.2404,  20.0029,   4.7832,\n",
       "           7.7984,  13.3221,   7.6160],\n",
       "        [  8.0374,  -0.0956,  -8.7972,  -1.0999, -23.0011,  16.9435,  -1.0783,\n",
       "          16.6055,  12.9367,  13.9329],\n",
       "        [ 17.9865,   2.6376,  -4.3180,  -1.7109, -16.9843,  15.4072,  -0.6245,\n",
       "          14.0800,  20.9981,  15.0337],\n",
       "        [ 10.7016,  -4.0518,  -9.3863,  -8.7985, -13.2200,  14.6513,  -2.2296,\n",
       "          17.2295,  20.1443,  11.5757],\n",
       "        [ 14.6510,  -2.9706, -10.3531,   2.6913, -17.9774,  14.1735,   1.3325,\n",
       "          24.1135,  13.6223,   3.5045],\n",
       "        [  6.5005,   2.3753,  -5.5986,  -0.8971, -22.1439,   8.1203,   6.2159,\n",
       "          17.5114,  13.2429,  15.0865]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hid = sigmoid(torch.mm(inputs, w1) + b1)\n",
    "out = torch.mm(hid, w2) + b2\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x), dim=1).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Here, out should be the output of the network in the previous excercise with shape (64,10)\n",
    "probabilities = softmax(out)\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0169e-06, 6.7534e-04, 3.3153e-09, 5.1747e-12, 6.7661e-17, 1.8819e-03,\n",
       "         7.9861e-08, 4.0265e-01, 4.8658e-01, 1.0821e-01],\n",
       "        [3.7758e-09, 3.5380e-12, 1.3530e-13, 1.3442e-13, 2.5164e-18, 9.9985e-01,\n",
       "         1.0639e-07, 8.0193e-05, 7.0955e-05, 1.5398e-07],\n",
       "        [6.7988e-06, 4.8516e-10, 2.0296e-13, 3.6905e-12, 4.0120e-19, 1.2108e-02,\n",
       "         5.3087e-09, 9.8765e-01, 2.1106e-04, 2.4167e-05],\n",
       "        [2.0536e-06, 1.5619e-10, 1.8598e-14, 1.6206e-14, 2.5456e-18, 1.0551e-04,\n",
       "         3.8073e-06, 1.0712e-03, 3.4378e-01, 6.5504e-01],\n",
       "        [1.5705e-04, 4.6561e-08, 3.0026e-10, 7.0775e-09, 1.0857e-19, 6.4174e-04,\n",
       "         2.1211e-09, 9.9915e-01, 1.0666e-05, 4.1862e-05],\n",
       "        [2.4346e-05, 4.5397e-09, 5.8912e-10, 4.1492e-12, 9.8055e-17, 9.9099e-03,\n",
       "         2.7752e-06, 6.2336e-01, 3.6667e-01, 3.9489e-05],\n",
       "        [4.5654e-03, 5.0470e-10, 1.2302e-09, 8.7480e-11, 1.3514e-18, 3.0644e-01,\n",
       "         4.9575e-07, 3.9859e-03, 6.8498e-01, 3.2248e-05],\n",
       "        [4.1307e-08, 4.7381e-11, 3.9625e-14, 4.9794e-13, 5.2396e-18, 9.6678e-01,\n",
       "         5.2600e-10, 3.3023e-02, 8.5681e-05, 1.1313e-04],\n",
       "        [2.9588e-08, 1.3956e-10, 2.4994e-12, 4.3536e-07, 2.5149e-17, 1.1235e-03,\n",
       "         1.3901e-05, 9.8509e-01, 7.2593e-03, 6.5174e-03],\n",
       "        [1.4138e-06, 6.8016e-08, 1.5120e-12, 1.1057e-09, 1.8016e-19, 8.0789e-01,\n",
       "         2.3579e-06, 8.7831e-06, 6.8768e-03, 1.8522e-01],\n",
       "        [8.5122e-06, 1.5469e-10, 3.3587e-15, 9.7527e-12, 1.4280e-19, 9.8903e-01,\n",
       "         3.9731e-05, 1.0574e-02, 5.7780e-05, 2.9062e-04],\n",
       "        [1.6848e-03, 6.8409e-13, 8.0830e-10, 1.1924e-11, 6.8517e-18, 9.6672e-01,\n",
       "         8.0518e-14, 1.3521e-04, 3.1463e-02, 2.1049e-08],\n",
       "        [4.2000e-10, 2.1882e-13, 9.5503e-18, 4.9199e-11, 1.4879e-19, 4.9566e-06,\n",
       "         6.1186e-05, 3.6565e-09, 9.9993e-01, 5.0135e-07],\n",
       "        [2.0208e-01, 1.5291e-07, 5.6249e-15, 2.1944e-07, 6.9385e-18, 7.6956e-01,\n",
       "         1.1717e-02, 4.4363e-03, 1.0573e-02, 1.6301e-03],\n",
       "        [4.6907e-01, 8.8695e-06, 1.1804e-12, 2.7794e-11, 8.9034e-18, 4.6950e-05,\n",
       "         7.2313e-03, 1.8694e-01, 3.3671e-01, 1.2571e-08],\n",
       "        [6.9828e-04, 1.4035e-10, 1.1502e-07, 1.6709e-10, 2.0700e-18, 8.3462e-03,\n",
       "         7.9421e-01, 1.4630e-06, 1.0170e-02, 1.8657e-01],\n",
       "        [6.5645e-03, 5.1525e-04, 7.5689e-11, 2.5898e-03, 1.0639e-10, 9.0733e-04,\n",
       "         4.2652e-08, 8.1042e-01, 1.7586e-01, 3.1500e-03],\n",
       "        [9.5510e-01, 1.2703e-05, 1.4686e-08, 7.6221e-08, 7.1286e-14, 1.6316e-03,\n",
       "         3.5588e-02, 2.2456e-03, 5.3275e-03, 9.8606e-05],\n",
       "        [7.7657e-03, 8.0752e-10, 7.9211e-12, 5.6444e-10, 1.2349e-17, 1.4861e-02,\n",
       "         6.6981e-07, 9.7705e-01, 3.2454e-04, 1.5556e-06],\n",
       "        [1.3696e-05, 7.8821e-06, 1.7261e-10, 3.1072e-09, 3.8860e-16, 9.9957e-01,\n",
       "         2.5141e-05, 2.8637e-04, 9.5838e-05, 3.6911e-06],\n",
       "        [1.7932e-07, 4.6366e-10, 9.3394e-15, 4.6845e-10, 6.1060e-16, 4.3883e-03,\n",
       "         1.2024e-06, 4.5128e-11, 9.9561e-01, 2.6308e-06],\n",
       "        [5.6178e-05, 1.1700e-08, 2.2298e-06, 6.0098e-09, 4.3522e-16, 7.5142e-01,\n",
       "         7.8618e-03, 7.3453e-06, 2.2534e-01, 1.5316e-02],\n",
       "        [5.7087e-06, 2.7265e-10, 1.6498e-11, 3.4035e-09, 2.5589e-19, 5.1150e-05,\n",
       "         1.0013e-07, 7.9509e-01, 2.7530e-04, 2.0458e-01],\n",
       "        [1.1561e-06, 4.0236e-10, 1.6092e-07, 8.7687e-07, 2.5574e-14, 5.3420e-01,\n",
       "         3.6856e-01, 4.2791e-03, 7.6411e-02, 1.6547e-02],\n",
       "        [9.0219e-12, 2.0146e-14, 2.4537e-13, 7.3427e-14, 2.5939e-15, 9.2484e-01,\n",
       "         2.4229e-08, 5.7815e-04, 3.7638e-05, 7.4541e-02],\n",
       "        [2.6008e-06, 1.3558e-08, 5.3744e-13, 1.1578e-09, 2.4433e-15, 9.9974e-01,\n",
       "         2.3835e-04, 9.4091e-07, 3.5521e-06, 1.2923e-05],\n",
       "        [4.6056e-08, 2.8420e-10, 1.7020e-11, 1.9049e-11, 3.9698e-19, 7.8749e-07,\n",
       "         4.0954e-06, 6.1061e-03, 9.9344e-01, 4.4473e-04],\n",
       "        [5.1623e-04, 6.6073e-09, 1.2159e-13, 1.3349e-05, 1.7053e-15, 1.1082e-04,\n",
       "         1.6793e-06, 9.9881e-01, 5.5079e-04, 4.5433e-07],\n",
       "        [3.3545e-06, 9.0471e-10, 1.4408e-13, 5.8215e-13, 2.2235e-19, 9.8125e-01,\n",
       "         9.5547e-06, 1.8686e-02, 4.8149e-05, 6.7293e-09],\n",
       "        [3.2262e-05, 1.5533e-09, 3.6126e-11, 5.8767e-10, 2.6866e-17, 1.3919e-02,\n",
       "         1.8986e-04, 7.4563e-01, 2.2214e-01, 1.8089e-02],\n",
       "        [9.1832e-08, 5.1707e-18, 3.2738e-18, 5.3058e-19, 4.6329e-26, 1.0000e+00,\n",
       "         4.8048e-14, 1.3138e-06, 5.7222e-10, 1.0483e-12],\n",
       "        [1.9569e-07, 4.0944e-09, 1.4613e-09, 2.6251e-09, 1.3649e-09, 8.2242e-02,\n",
       "         5.3852e-05, 4.7105e-05, 9.1735e-01, 3.0581e-04],\n",
       "        [8.8730e-06, 6.9907e-13, 4.4144e-11, 4.8198e-09, 2.6047e-19, 1.0011e-06,\n",
       "         3.5083e-04, 4.4842e-01, 5.4695e-01, 4.2686e-03],\n",
       "        [2.1794e-05, 3.7629e-10, 6.8060e-07, 2.4238e-10, 4.4338e-16, 5.3897e-01,\n",
       "         1.1234e-03, 6.0844e-03, 4.5376e-01, 3.1968e-05],\n",
       "        [4.8140e-07, 2.7688e-09, 5.0908e-13, 2.6863e-13, 4.0420e-15, 5.4837e-02,\n",
       "         9.4603e-08, 5.2164e-02, 8.9151e-01, 1.4924e-03],\n",
       "        [2.4687e-07, 6.3963e-12, 1.0013e-11, 4.3676e-09, 9.6750e-18, 8.4975e-03,\n",
       "         1.3189e-03, 2.9269e-04, 9.8988e-01, 1.3337e-05],\n",
       "        [7.6728e-05, 2.2146e-09, 3.6730e-07, 6.9885e-09, 7.0359e-15, 1.3449e-01,\n",
       "         2.2900e-04, 3.9250e-03, 5.7222e-01, 2.8906e-01],\n",
       "        [2.6789e-06, 8.5053e-08, 1.8882e-15, 8.0929e-06, 2.9171e-11, 8.8501e-07,\n",
       "         1.3403e-05, 3.3391e-01, 6.6588e-01, 1.8415e-04],\n",
       "        [8.4381e-07, 4.4144e-06, 1.4417e-09, 6.1999e-15, 2.1284e-15, 9.9321e-01,\n",
       "         1.7234e-06, 1.0147e-06, 6.7576e-03, 2.3955e-05],\n",
       "        [5.1046e-06, 5.8907e-11, 9.5251e-16, 2.6410e-13, 2.1327e-22, 2.1361e-06,\n",
       "         4.2479e-06, 4.2481e-03, 9.9574e-01, 4.7321e-07],\n",
       "        [8.9133e-07, 1.9601e-11, 1.3722e-12, 1.2970e-10, 3.7568e-17, 9.3446e-01,\n",
       "         2.0612e-08, 1.7831e-05, 6.5519e-02, 1.2177e-07],\n",
       "        [6.7166e-06, 1.3876e-07, 1.4752e-07, 9.6665e-10, 2.1119e-12, 6.0663e-02,\n",
       "         9.6826e-05, 7.7717e-01, 1.6206e-01, 3.5504e-06],\n",
       "        [1.9632e-09, 2.2581e-14, 3.3152e-12, 2.6780e-12, 7.2195e-17, 1.0000e+00,\n",
       "         1.8947e-14, 2.0496e-10, 6.4507e-08, 9.8306e-08],\n",
       "        [2.1358e-04, 7.8556e-10, 2.1202e-09, 4.9489e-09, 1.9553e-15, 6.9511e-01,\n",
       "         4.9670e-06, 3.0453e-01, 1.2345e-04, 2.1607e-05],\n",
       "        [1.3055e-04, 3.7661e-10, 2.4691e-09, 8.7343e-08, 7.6672e-15, 4.7172e-04,\n",
       "         1.0094e-02, 7.4707e-01, 2.4126e-01, 9.7618e-04],\n",
       "        [9.1463e-03, 1.0068e-06, 3.4166e-14, 6.0739e-10, 3.5458e-19, 4.7598e-02,\n",
       "         2.8456e-06, 9.4323e-01, 1.2922e-05, 5.4536e-06],\n",
       "        [2.1097e-07, 3.2141e-15, 2.6414e-17, 2.1747e-10, 5.9738e-20, 1.0446e-04,\n",
       "         5.7308e-08, 7.4527e-02, 9.2536e-01, 4.0493e-06],\n",
       "        [6.3149e-10, 9.7655e-11, 8.6740e-14, 1.6554e-09, 6.0814e-18, 1.7374e-09,\n",
       "         5.7281e-03, 9.9291e-01, 1.3579e-03, 8.4796e-07],\n",
       "        [3.7732e-06, 1.6237e-08, 1.6229e-12, 2.7119e-12, 4.3709e-15, 7.4387e-03,\n",
       "         1.0411e-05, 1.3849e-03, 9.9027e-01, 8.9458e-04],\n",
       "        [2.8784e-07, 2.6910e-10, 4.5039e-11, 1.0755e-11, 6.2402e-14, 7.9076e-02,\n",
       "         1.5192e-07, 7.8388e-01, 3.4442e-02, 1.0260e-01],\n",
       "        [1.0554e-05, 8.1547e-06, 9.4668e-07, 1.6267e-11, 4.6609e-14, 7.4160e-01,\n",
       "         2.0173e-04, 1.5602e-01, 1.0214e-01, 2.4293e-05],\n",
       "        [3.5784e-06, 5.1124e-10, 4.9139e-11, 2.3213e-10, 1.6453e-19, 8.9604e-06,\n",
       "         7.2374e-06, 8.6285e-01, 1.3485e-01, 2.2762e-03],\n",
       "        [3.3761e-05, 6.0942e-08, 9.6967e-12, 3.1273e-08, 1.2066e-16, 2.3934e-01,\n",
       "         1.6441e-04, 8.4688e-02, 6.4301e-01, 3.2766e-02],\n",
       "        [1.2582e-10, 6.9545e-10, 1.0584e-09, 2.8718e-04, 5.2748e-13, 9.7486e-06,\n",
       "         9.3468e-03, 1.3912e-01, 7.6429e-01, 8.6947e-02],\n",
       "        [8.3939e-05, 2.2945e-06, 2.9868e-11, 4.1262e-09, 4.7373e-14, 8.7355e-01,\n",
       "         5.0401e-06, 1.2233e-01, 3.6132e-04, 3.6657e-03],\n",
       "        [5.0393e-09, 9.2299e-12, 1.4430e-16, 5.4494e-14, 9.1860e-22, 1.1835e-05,\n",
       "         2.6161e-10, 4.2240e-04, 9.9957e-01, 5.7683e-13],\n",
       "        [6.7548e-01, 2.3709e-10, 1.0665e-08, 2.4843e-12, 4.1883e-20, 3.2336e-01,\n",
       "         3.7878e-06, 1.0492e-03, 1.1132e-04, 4.3416e-08],\n",
       "        [6.2178e-05, 7.9941e-05, 2.9422e-11, 5.2247e-14, 8.3939e-15, 5.7318e-01,\n",
       "         1.0325e-09, 3.9860e-01, 5.1844e-06, 2.8077e-02],\n",
       "        [4.9642e-06, 5.3892e-08, 2.0981e-12, 3.1290e-10, 2.6957e-14, 9.9873e-01,\n",
       "         2.4525e-07, 5.0015e-06, 1.2532e-03, 4.1679e-06],\n",
       "        [7.6122e-05, 2.2356e-08, 3.7183e-12, 8.1893e-09, 2.5216e-18, 5.6153e-01,\n",
       "         8.3678e-09, 4.0051e-01, 1.0215e-02, 2.7664e-02],\n",
       "        [4.6581e-02, 1.0053e-08, 9.5824e-12, 1.2994e-10, 3.0241e-17, 3.5322e-03,\n",
       "         3.8508e-10, 9.3676e-04, 9.4652e-01, 2.4313e-03],\n",
       "        [7.4877e-05, 2.9311e-11, 1.4136e-13, 2.5443e-13, 3.0574e-15, 3.8875e-03,\n",
       "         1.8131e-10, 5.1216e-02, 9.4464e-01, 1.7946e-04],\n",
       "        [7.7703e-05, 1.7277e-12, 1.0746e-15, 4.9703e-10, 5.2493e-19, 4.8199e-05,\n",
       "         1.2773e-10, 9.9985e-01, 2.7775e-05, 1.1209e-09],\n",
       "        [1.4983e-05, 2.4212e-07, 8.3371e-11, 9.1804e-09, 5.4390e-18, 7.5695e-05,\n",
       "         1.1272e-05, 9.0694e-01, 1.2700e-02, 8.0254e-02]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "source": [
    "## Building network for text recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network and look at it's text representation\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "class Network1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        # Second hidden\n",
    "        self.hidden2 = nn.Linear(128, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 1 hidden layer with relu activation\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        # 2 hidden layer with relu activation\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network1(\n",
       "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network1()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0005, -0.0351, -0.0133,  ..., -0.0033,  0.0299,  0.0124],\n",
      "        [ 0.0356, -0.0150, -0.0306,  ..., -0.0139, -0.0245,  0.0298],\n",
      "        [ 0.0018, -0.0095, -0.0248,  ..., -0.0255, -0.0291, -0.0105],\n",
      "        ...,\n",
      "        [ 0.0123, -0.0051,  0.0343,  ..., -0.0214, -0.0213,  0.0200],\n",
      "        [-0.0054,  0.0067, -0.0009,  ...,  0.0138, -0.0028, -0.0189],\n",
      "        [-0.0072,  0.0278, -0.0215,  ...,  0.0309,  0.0095,  0.0079]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0203,  0.0106, -0.0261,  0.0285,  0.0132, -0.0233, -0.0356,  0.0184,\n",
      "         0.0154, -0.0243,  0.0159, -0.0350, -0.0104, -0.0164,  0.0169, -0.0061,\n",
      "        -0.0227,  0.0279,  0.0139,  0.0118, -0.0152,  0.0296, -0.0042, -0.0106,\n",
      "        -0.0009,  0.0057,  0.0129, -0.0151, -0.0129,  0.0183, -0.0024, -0.0073,\n",
      "        -0.0240, -0.0127,  0.0032,  0.0001, -0.0257, -0.0202,  0.0109,  0.0240,\n",
      "         0.0222, -0.0125,  0.0029,  0.0140,  0.0059, -0.0069,  0.0191,  0.0007,\n",
      "        -0.0173, -0.0108,  0.0035,  0.0155,  0.0146,  0.0076,  0.0088,  0.0094,\n",
      "        -0.0301, -0.0064,  0.0354, -0.0337,  0.0124, -0.0105,  0.0136,  0.0159,\n",
      "        -0.0136,  0.0246, -0.0226,  0.0035, -0.0329, -0.0177, -0.0047,  0.0344,\n",
      "         0.0047,  0.0234,  0.0184, -0.0224,  0.0316,  0.0043, -0.0019, -0.0075,\n",
      "        -0.0233, -0.0186,  0.0090,  0.0025, -0.0169, -0.0198, -0.0045,  0.0028,\n",
      "         0.0059, -0.0245, -0.0104, -0.0019, -0.0046,  0.0331, -0.0023,  0.0188,\n",
      "         0.0035, -0.0058,  0.0050, -0.0105, -0.0118, -0.0022,  0.0274,  0.0122,\n",
      "         0.0280,  0.0085,  0.0275,  0.0166,  0.0302, -0.0071,  0.0108,  0.0085,\n",
      "         0.0338,  0.0276, -0.0099,  0.0153, -0.0083,  0.0195,  0.0021, -0.0048,\n",
      "        -0.0226, -0.0351,  0.0274,  0.0337, -0.0024, -0.0260, -0.0080,  0.0303],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0742, -0.0348,  0.0300,  ..., -0.0816, -0.0356,  0.0051],\n",
      "        [ 0.0631, -0.0183, -0.0478,  ..., -0.0541, -0.0475,  0.0154],\n",
      "        [-0.0210, -0.0823, -0.0340,  ..., -0.0295, -0.0733, -0.0774],\n",
      "        ...,\n",
      "        [ 0.0791,  0.0288, -0.0615,  ..., -0.0564, -0.0637, -0.0316],\n",
      "        [-0.0812,  0.0259,  0.0204,  ...,  0.0042,  0.0199, -0.0799],\n",
      "        [ 0.0089, -0.0686,  0.0714,  ...,  0.0174, -0.0567,  0.0721]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0836,  0.0632,  0.0628, -0.0476,  0.0740, -0.0578,  0.0520, -0.0027,\n",
      "        -0.0125,  0.0654,  0.0733, -0.0348,  0.0635, -0.0181, -0.0396,  0.0743,\n",
      "        -0.0421,  0.0741, -0.0493,  0.0408,  0.0116, -0.0189, -0.0249, -0.0784,\n",
      "         0.0840,  0.0193, -0.0493, -0.0831, -0.0773,  0.0364, -0.0249,  0.0124,\n",
      "        -0.0612,  0.0106,  0.0167, -0.0488, -0.0642,  0.0017,  0.0825, -0.0810,\n",
      "         0.0856, -0.0256, -0.0088,  0.0417,  0.0316,  0.0579, -0.0817, -0.0759,\n",
      "        -0.0737,  0.0173,  0.0394,  0.0705,  0.0363, -0.0090, -0.0091, -0.0530,\n",
      "         0.0457,  0.0586, -0.0525,  0.0518, -0.0492, -0.0207,  0.0541, -0.0623],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.hidden1.weight)\n",
    "print(model.hidden1.bias)\n",
    "print(model.hidden2.weight)\n",
    "print(model.hidden2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "tensor(2.2971, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "print(model)\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get the data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass\n",
    "logits = model(images)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "source": [
    "## Network Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b9b005faa6cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m transform = transforms.Compose([transforms.ToTensor(),\n\u001b[0m\u001b[1;32m      2\u001b[0m                               \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               ])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9165062342625436\n",
      "Training loss: 0.8522378489343342\n",
      "Training loss: 0.5235032586972597\n",
      "Training loss: 0.4269198602609543\n",
      "Training loss: 0.3825194837410313\n",
      "Training loss: 0.3558722241505631\n",
      "Training loss: 0.3375131562193319\n",
      "Training loss: 0.3232306465903706\n",
      "Training loss: 0.31178819408008795\n",
      "Training loss: 0.30212394501577056\n",
      "Training loss: 0.29327114293776724\n",
      "Training loss: 0.2861143695647274\n",
      "Training loss: 0.2786511334815005\n",
      "Training loss: 0.2719529879642829\n",
      "Training loss: 0.26518515482354266\n",
      "Training loss: 0.2590887011733772\n",
      "Training loss: 0.2532401323509115\n",
      "Training loss: 0.24749537739259347\n",
      "Training loss: 0.241735609963155\n",
      "Training loss: 0.23610079841318923\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 20\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        # Gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "outputHidden": false,
    "inputHidden": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 423.0,
       "height": 226.0
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "logps = model.forward(img)\n",
    "\n",
    "ps = torch.exp(logps)\n",
    "halper.view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
