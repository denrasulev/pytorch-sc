{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basics\n",
        "\nThis is notebook for excersises with [PyTorch](https://pytorch.ord) framework."
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import modules\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import torch\n",
        "import halper\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchvision import datasets, transforms"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define activation functions\n",
        "def sigmoid(x):\n",
        "    \"\"\"Sigmoid activation function\"\"\"\n",
        "    return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    \"\"\"TanH (Hyperbolic Tangent Function) activation function\"\"\"\n",
        "    return torch.tanh(x)\n",
        "\nrelu = nn.ReLU()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Neuron"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random data\n",
        "torch.manual_seed(7)\n",
        "\n",
        "# Init features, weights, bias\n",
        "features = torch.randn(1, 5)\n",
        "weights = torch.randn_like(features)\n",
        "bias = torch.randn(1, 1)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Features: \", features)\n",
        "print(\"Weights: \", weights)\n",
        "print(\"Bias: \", bias)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features:  tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
            "Weights:  tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]])\n",
            "Bias:  tensor([[0.3177]])\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate output\n",
        "y = sigmoid(torch.sum(features * weights) + bias)\n",
        "y"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": [
              "tensor([[0.1595]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate output using matrix multiplication\n",
        "y = sigmoid(torch.mm(features, weights.view(5,1)) + bias)\n",
        "y"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": [
              "tensor([[0.1595]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stack neurons to layers"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the structure\n",
        "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
        "n_hidden = 2                    # Number of hidden units \n",
        "n_output = 1                    # Number of output units\n",
        "\n",
        "# Weights for inputs to hidden layer\n",
        "W1 = torch.randn(n_input, n_hidden)\n",
        "# Weights for hidden layer to output layer\n",
        "W2 = torch.randn(n_hidden, n_output)\n",
        "\n",
        "# Bias terms for hidden and output layers\n",
        "B1 = torch.randn(1, n_hidden)\n",
        "B2 = torch.randn(1, n_output)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Features: \", features)\n",
        "print(\"Input: \", features.shape[1])\n",
        "print(\"W1: \", W1)\n",
        "print(\"W2: \", W2)\n",
        "print(\"B1: \", B1)\n",
        "print(\"B2: \", B2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features:  tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
            "Input:  5\n",
            "W1:  tensor([[0.1328, 0.1373],\n",
            "        [0.2405, 1.3955],\n",
            "        [1.3470, 2.4382],\n",
            "        [0.2028, 2.4505],\n",
            "        [2.0256, 1.7792]])\n",
            "W2:  tensor([[-0.9179],\n",
            "        [-0.4578]])\n",
            "B1:  tensor([[-0.7245,  1.2799]])\n",
            "B2:  tensor([[-0.9941]])\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = relu(torch.mm(features, W1) + B1)\n",
        "y = sigmoid(torch.mm(h, W2) + B2)\n",
        "y"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": [
              "tensor([[0.0011]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network for image number recognition"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transformations to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x11a908b70>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": [
              "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\n"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 253,
              "height": 250
            }
          }
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the structure\n",
        "n_inp = 784    # Number of input units\n",
        "n_hid = 256    # Number of hidden units \n",
        "n_out = 10     # Number of output units\n",
        "\n",
        "inputs = images.view(images.shape[0], -1)\n",
        "\n",
        "# Weights for inputs to hidden layer\n",
        "w1 = torch.randn(n_inp, n_hid)\n",
        "w2 = torch.randn(n_hid, n_out)\n",
        "\n",
        "# Bias terms for hidden and output layers\n",
        "b1 = torch.randn(1, n_hid)\n",
        "b2 = torch.randn(1, n_out)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hid = sigmoid(torch.mm(inputs, w1) + b1)\n",
        "out = torch.mm(hid, w2) + b2\n",
        "out"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": [
              "tensor([[  3.4650,  -9.3836,  -9.9485,   9.4702,  10.0684,  16.0961,  -6.2732,\n",
              "           2.8965,  -0.6581,   4.4914],\n",
              "        [ -3.4401,  -2.1008,  -1.0362,  14.2685,  -2.7966,  -0.1972,  -2.3134,\n",
              "           0.1276,  -3.9340,  10.3931],\n",
              "        [  4.1170,  -4.4916,  14.4495,   3.8711,  11.7530,   6.0813,  -6.8356,\n",
              "           4.0926,  -3.3715,  -1.5335],\n",
              "        [  0.9149,  -6.5682,   7.9304,  16.4015,  10.8328,   8.0136,  -4.4967,\n",
              "           4.8189,  -4.2965,   5.9058],\n",
              "        [  5.5597,  -8.4811,  -2.5871,  14.7395,  13.2668,  18.1413,   2.6496,\n",
              "          -1.2208,  -4.2804,   5.2748],\n",
              "        [ -2.9577, -10.8776,  -3.9198,  18.8121,  -0.8268,   9.4067,   5.6384,\n",
              "          10.1557,  -0.2571,   2.3656],\n",
              "        [ -0.4996,  -7.9370,  -1.3912,  11.4435,   5.0798,  13.4650,  -7.8572,\n",
              "           4.2008,  -8.0562,   0.5859],\n",
              "        [ -9.0681, -10.0080,   3.7154,  13.8048,   1.2239,  14.2243,  -5.0702,\n",
              "           0.3474,  -6.0579,   4.3319],\n",
              "        [  6.4393,  -4.9171,   3.4406,   6.0519,   1.9684,  12.3335,  -8.6811,\n",
              "           1.2472,  -3.7591, -10.4160],\n",
              "        [  5.6634, -10.0682,   2.2730,  11.4970,   5.3472,  14.5982,  -8.0017,\n",
              "           3.2794,  -8.5887,  -1.2972],\n",
              "        [  9.8805,  -6.1442,   2.1488,   5.4201,   9.5173,  12.1933, -10.3752,\n",
              "           6.0812,  -4.0606,   2.5781],\n",
              "        [ -0.6531, -10.3890,  -3.1183,   7.1513,  -2.8414,   8.1320,  -3.8749,\n",
              "          -1.7486, -10.7011,   5.5664],\n",
              "        [ -0.7464,  -1.7182,  -3.0089,  11.5711,   9.9044,   5.6587,  -3.3134,\n",
              "           3.0767,  -7.6369,   7.6800],\n",
              "        [  1.6177, -12.4694,   6.7346,   8.4178,  -0.2659,  16.9716,  -8.7770,\n",
              "           5.3667,  -3.2567,   8.1929],\n",
              "        [  4.9722,  -6.6695,  -3.1642,   9.0501,  12.4941,   9.1199, -14.9193,\n",
              "           1.6467,   1.4794,  -0.8825],\n",
              "        [  4.9988,  -3.4369,   2.6283,  19.0066,   0.1855,   2.8032,  -1.4617,\n",
              "           8.4636, -17.0639,  16.8554],\n",
              "        [ -1.3612,  -4.6124,   2.6705,  21.1288,  16.0836,  18.9987,  -8.1155,\n",
              "          -3.6153, -10.0802,  -4.0005],\n",
              "        [  1.8323,  -7.7606,   9.9934,  15.7434,  11.2658,  14.1145, -13.4353,\n",
              "           3.3888,  -5.5876,   9.5380],\n",
              "        [  0.9213, -14.1788,  -6.3941,   9.5883,  10.3485,   8.2500, -12.8072,\n",
              "           4.5957,  -8.1680,   1.1760],\n",
              "        [  3.2893,  -8.2711,  -3.1745,  16.0809,   7.3629,  13.7375,  -3.6699,\n",
              "           2.8039,  -3.1520,  -0.4624],\n",
              "        [-10.2083,  -1.6496,   7.4481,   9.1081,   8.6488,   7.4247,  -0.9105,\n",
              "           0.2368,  -7.5741,   9.3095],\n",
              "        [  0.3885,  -4.0716,   2.4839,  12.7385,   3.2568,   7.3418,  -2.9452,\n",
              "           2.3652, -11.4246,   3.7697],\n",
              "        [  8.1698,  -9.1844,   2.6880,  13.4460,   8.6919,  10.4023,  -3.8376,\n",
              "           0.9964,   0.9184,  -1.1486],\n",
              "        [ -8.4137, -11.7941,  -3.3082,  25.1797,   1.3829, -12.4582,  -1.3677,\n",
              "          -0.6682,  -6.4823,   3.6995],\n",
              "        [ 11.2993,  -5.9577,  -3.7721,  10.7208,   7.8457,  10.0508,  -4.6138,\n",
              "           9.2859,  -5.3715,  11.4617],\n",
              "        [ -8.9960,  -4.7662,   0.5731,  10.7552,  20.0164,   3.5131,  -5.2754,\n",
              "           4.7317,  -3.2768,   9.7260],\n",
              "        [  3.3725,   9.7620,  -5.2024,   6.5165,   9.4581,   7.9484,  -2.4680,\n",
              "           6.4242,  -4.9818,  -3.8773],\n",
              "        [  8.1269, -20.4116,  11.1738,  15.2511,   8.6342,  15.1210,  -0.4640,\n",
              "           2.8238,   4.9828,  -0.6507],\n",
              "        [  1.1243,  -9.9593,  -0.6195,   9.8313,   1.5184,  -2.2306,  -2.1291,\n",
              "           0.0417,  -8.9318,   6.9456],\n",
              "        [  8.9173,  -2.5679,   4.5162,  15.3495,   7.8426,  17.9575,  -0.1816,\n",
              "           1.0095,  -0.0848,  -1.9880],\n",
              "        [ -4.6738,  -5.4722,  -8.8900,  13.4761,  -4.8044,   7.7520,  -5.4584,\n",
              "           6.0388, -10.0852,   2.3586],\n",
              "        [  1.0566,  -5.1598,   4.6004,  -3.0893,  12.0334,  19.6030,  -6.0030,\n",
              "           4.5493,  -0.6232,   2.4609],\n",
              "        [  5.5093,  -8.4663,   4.2138,  13.6858,   0.9384,  10.6185,   0.7652,\n",
              "           1.3268,   3.5789,  -2.2891],\n",
              "        [  4.6281,  -6.3972,  -5.0232,  12.9147,   3.3491,  10.9264,   5.9718,\n",
              "           7.0483,   1.4803,  -1.0988],\n",
              "        [ -3.4776,  -1.8740,  -2.4098,  15.1372,  -5.3944,   2.2379,  -5.2838,\n",
              "          -1.8684,  -7.4143,   8.6975],\n",
              "        [  4.0933,  -3.4457,  10.3129,   7.6624,  11.3639,   5.3994,  -1.5544,\n",
              "          -1.4543, -10.1752,   8.6625],\n",
              "        [ -0.2687, -10.4769,  -9.0083,   5.8984,  -0.5384,   9.6176,  -3.0756,\n",
              "           4.5391,   2.8310,   6.1127],\n",
              "        [  3.6880,  -6.8336,  -8.5963,   7.8039,  14.8596,  14.6028,  -2.4162,\n",
              "           3.2839,  -9.2258,   7.5899],\n",
              "        [ -0.0294, -22.2228,   5.2770,  19.8922,   5.9748,  12.4769,  -2.8963,\n",
              "           6.2201,  -4.2958,   9.8922],\n",
              "        [  8.4251,  -5.3465,   0.8223,   6.8623,   6.4341,   8.9708,  -1.7066,\n",
              "          -4.4196,  -7.1453,   0.0100],\n",
              "        [  0.8051,  -9.4580,   7.7636,  -4.4327,   5.4193,  17.6477,   3.5168,\n",
              "          -1.9512,   1.8057,  -5.2380],\n",
              "        [  4.9153, -14.6698,  -4.1093,   8.5050,   1.2333,  -1.8186,   4.0345,\n",
              "          -1.9763,  -7.0691,   9.4693],\n",
              "        [ -4.6042, -12.6449,  -2.8894,  13.8790,   6.1601,   7.2313,  -1.3886,\n",
              "          12.2387,  -6.6991,   3.6842],\n",
              "        [ -0.0075, -10.6153,   0.6399,  18.7381,   2.0087,   1.1161,  -3.1142,\n",
              "           0.6799,   0.8749,   9.6144],\n",
              "        [  1.4813,  -4.6129,   2.6139,   0.0162,  10.3542,  12.3338,   3.4080,\n",
              "           4.6844,  -8.9090,   5.8472],\n",
              "        [  1.9632,  -5.1203,   3.8141,   8.5604,   2.1515,  22.1165,  -4.6799,\n",
              "          -0.3237, -12.8244,   0.9399],\n",
              "        [  2.3265,  -1.0751,  -2.2385,   7.2979,  13.6236,   5.1401,   1.1429,\n",
              "          -7.0797, -11.0994,   5.0931],\n",
              "        [ -4.3095,  -3.7744,   0.6421,   2.1755,   4.8157,  15.8974,   2.2678,\n",
              "           1.0919,  -9.2446,   8.0902],\n",
              "        [ -4.0113,  -2.4192,  -7.2651,  17.1998,   4.7852,  15.1130, -12.9353,\n",
              "           9.6234,  -4.5860,   5.7988],\n",
              "        [  2.1132,   6.9704,  -5.8633,   4.5701,   1.9720,   1.4381,  -1.5894,\n",
              "           4.2028,  -8.4800,   3.3838],\n",
              "        [  0.0147,   0.8915,  -5.0752,  12.7478,   1.3799,   4.0466,  -8.2769,\n",
              "           1.5594,  -0.4787,  -2.4280],\n",
              "        [ 11.0626,  -5.9204,   5.8049,  10.4535,   3.9526,  16.2124,  -0.6611,\n",
              "           2.1300,  -1.2701,  -4.9473],\n",
              "        [ -2.3270,  -5.3961,  -0.2760,   8.6471,  11.0543,  10.7973,  12.0753,\n",
              "          -1.5470, -10.2941,   7.1438],\n",
              "        [  7.0172,  -7.4412,  -7.7968,  10.2105,   9.7381,   9.0319,  -0.2446,\n",
              "          -8.0121,  -1.6995,  -1.5819],\n",
              "        [ -6.2742,  -5.8943, -18.3452,  17.0004,   5.3362,  13.4546,  -7.9091,\n",
              "           0.4831,   3.1494,   9.8565],\n",
              "        [  9.1696,  -6.4805,  -2.1090,   8.7813,  11.7142,   5.1901,   3.1532,\n",
              "           5.2939, -13.2318,   8.9420],\n",
              "        [  1.8969,   1.4201,   3.9729,   4.1646,  -0.4488,  13.5433,  -5.6836,\n",
              "           2.9539,  -9.5445,   8.1304],\n",
              "        [ -7.2719,  -6.7119,  -1.8188,  -0.0514,   7.3943,   9.2506,  -1.6577,\n",
              "           4.8228,  -6.0182,   3.6435],\n",
              "        [  6.5153,  -9.7512,   6.4832,  14.5796,   1.5587,  10.2176, -12.3016,\n",
              "           5.2696,  -7.4145,   4.5314],\n",
              "        [  0.0264,  -6.3685,   1.9302,  12.0039,   8.6076,  16.7414,   5.5566,\n",
              "          -1.5520, -13.3537,   0.4534],\n",
              "        [  1.6457, -11.0790,  -0.9715,  11.5546,   8.8093,   9.0704,   2.4349,\n",
              "          -3.0984,  -8.2728,   2.1350],\n",
              "        [  4.8833,   1.5787,  -0.9140,   3.8675,   9.3957,   4.7036,  -0.1388,\n",
              "           0.4416,  -6.0187,   0.1731],\n",
              "        [ -1.4583,   0.1101,  -1.1471,   8.6742,   7.8046,  12.8374,  -7.1687,\n",
              "           3.2689,  -8.2008,   1.2615],\n",
              "        [ 12.0028, -16.4631,   1.9391,  17.0312,   4.1717,   5.6700,  -5.5374,\n",
              "           1.4408,  -0.2766,   9.2432]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.sum(torch.exp(x), dim=1).view(-1, 1)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, out should be the output of the network in the previous excercise with shape (64,10)\n",
        "probabilities = softmax(out)\n",
        "# Does it have the right shape? Should be (64, 10)\n",
        "print(probabilities.shape)\n",
        "# Does it sum to 1?\n",
        "print(probabilities.sum(dim=1))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": [
              "tensor([[3.2564e-06, 8.5643e-12, 4.8680e-12, 1.3206e-03, 2.4021e-03, 9.9626e-01,\n",
              "         1.9210e-10, 1.8443e-06, 5.2736e-08, 9.0885e-06],\n",
              "        [1.9968e-08, 7.6205e-08, 2.2097e-07, 9.7967e-01, 3.8003e-08, 5.1135e-07,\n",
              "         6.1607e-08, 7.0757e-07, 1.2185e-08, 2.0324e-02],\n",
              "        [3.0492e-05, 5.5655e-09, 9.3654e-01, 2.3844e-05, 6.3163e-02, 2.1740e-04,\n",
              "         5.3401e-10, 2.9757e-05, 1.7060e-08, 1.0720e-07],\n",
              "        [1.8725e-07, 1.0532e-10, 2.0853e-04, 9.9573e-01, 3.7990e-03, 2.2663e-04,\n",
              "         8.3590e-10, 9.2876e-06, 1.0212e-09, 2.7538e-05],\n",
              "        [3.2994e-06, 2.6338e-12, 9.5572e-10, 3.2002e-02, 7.3385e-03, 9.6065e-01,\n",
              "         1.7973e-07, 3.7473e-09, 1.7576e-10, 2.4816e-06],\n",
              "        [3.5107e-10, 1.2759e-13, 1.3414e-10, 9.9974e-01, 2.9568e-09, 8.2257e-05,\n",
              "         1.8995e-06, 1.7396e-04, 5.2268e-09, 7.1986e-08],\n",
              "        [7.6051e-07, 4.4783e-10, 3.1182e-07, 1.1693e-01, 2.0147e-04, 8.8278e-01,\n",
              "         4.8500e-10, 8.3654e-05, 3.9751e-10, 2.2519e-06],\n",
              "        [4.6219e-11, 1.8055e-11, 1.6467e-05, 3.9663e-01, 1.3632e-06, 6.0332e-01,\n",
              "         2.5180e-09, 5.6739e-07, 9.3780e-10, 3.0503e-05],\n",
              "        [2.7423e-03, 3.2067e-08, 1.3670e-04, 1.8614e-03, 3.1362e-05, 9.9521e-01,\n",
              "         7.4371e-10, 1.5247e-05, 1.0209e-07, 1.3121e-10],\n",
              "        [1.2603e-04, 1.8550e-11, 4.2467e-06, 4.3051e-02, 9.1858e-05, 9.5672e-01,\n",
              "         1.4648e-10, 1.1617e-05, 8.1442e-11, 1.1954e-07],\n",
              "        [8.4503e-02, 9.2782e-09, 3.7072e-05, 9.7666e-04, 5.8768e-02, 8.5377e-01,\n",
              "         1.3489e-10, 1.8917e-03, 7.4531e-08, 5.6951e-05],\n",
              "        [1.0536e-04, 6.2288e-09, 8.9541e-06, 2.5827e-01, 1.1812e-05, 6.8863e-01,\n",
              "         4.2019e-06, 3.5229e-05, 4.5589e-09, 5.2935e-02],\n",
              "        [3.6899e-06, 1.3963e-06, 3.8410e-07, 8.2493e-01, 1.5581e-01, 2.2322e-03,\n",
              "         2.8326e-07, 1.6879e-04, 3.7542e-09, 1.6848e-02],\n",
              "        [2.1465e-07, 1.6358e-13, 3.5806e-05, 1.9273e-04, 3.2633e-08, 9.9961e-01,\n",
              "         6.5665e-12, 9.1173e-06, 1.6398e-09, 1.5391e-04],\n",
              "        [5.0723e-04, 4.4596e-09, 1.4846e-07, 2.9937e-02, 9.3742e-01, 3.2101e-02,\n",
              "         1.1652e-12, 1.8236e-05, 1.5428e-05, 1.4540e-06],\n",
              "        [7.3907e-07, 1.6036e-10, 6.9050e-08, 8.9576e-01, 6.0016e-09, 8.2249e-08,\n",
              "         1.1559e-09, 2.3628e-05, 1.9363e-16, 1.0422e-01],\n",
              "        [1.5187e-10, 5.8815e-12, 8.5593e-09, 8.8868e-01, 5.7233e-03, 1.0560e-01,\n",
              "         1.7707e-13, 1.5941e-11, 2.4823e-14, 1.0845e-11],\n",
              "        [7.4948e-07, 5.1119e-11, 2.6246e-03, 8.2459e-01, 9.3681e-03, 1.6174e-01,\n",
              "         1.7543e-13, 3.5539e-06, 4.4910e-10, 1.6644e-03],\n",
              "        [5.0516e-05, 1.3981e-11, 3.3604e-08, 2.9341e-01, 6.2753e-01, 7.6955e-02,\n",
              "         5.5107e-11, 1.9916e-03, 5.7017e-09, 6.5169e-05],\n",
              "        [2.5397e-06, 2.4221e-11, 3.9592e-09, 9.1227e-01, 1.4926e-04, 8.7573e-02,\n",
              "         2.4124e-09, 1.5630e-06, 4.0494e-09, 5.9627e-08],\n",
              "        [1.2638e-09, 6.5866e-06, 5.8849e-02, 3.0952e-01, 1.9553e-01, 5.7487e-02,\n",
              "         1.3793e-05, 4.3441e-05, 1.7608e-08, 3.7855e-01],\n",
              "        [4.3091e-06, 4.9814e-08, 3.5026e-05, 9.9522e-01, 7.5867e-05, 4.5098e-03,\n",
              "         1.5367e-07, 3.1106e-05, 3.1917e-11, 1.2670e-04],\n",
              "        [4.8159e-03, 1.3991e-10, 2.0043e-05, 9.4214e-01, 8.1178e-03, 4.4897e-02,\n",
              "         2.9372e-08, 3.6924e-06, 3.4153e-06, 4.3228e-07],\n",
              "        [2.5738e-15, 8.7595e-17, 4.2449e-13, 1.0000e+00, 4.6259e-11, 4.5088e-17,\n",
              "         2.9554e-12, 5.9484e-12, 1.7757e-14, 4.6910e-10],\n",
              "        [3.1357e-01, 1.0040e-08, 8.9309e-08, 1.7583e-01, 9.9188e-03, 8.9970e-02,\n",
              "         3.8492e-08, 4.1871e-02, 1.8043e-08, 3.6884e-01],\n",
              "        [2.5118e-13, 1.7258e-11, 3.5959e-09, 9.5022e-05, 9.9987e-01, 6.8022e-08,\n",
              "         1.0371e-11, 2.3008e-07, 7.6529e-11, 3.3952e-05],\n",
              "        [8.4929e-04, 5.0578e-01, 1.6034e-07, 1.9699e-02, 3.7323e-01, 8.2475e-02,\n",
              "         2.4692e-06, 1.7963e-02, 1.9990e-07, 6.0324e-07],\n",
              "        [4.2453e-04, 1.7131e-16, 8.9356e-03, 5.2712e-01, 7.0502e-04, 4.6279e-01,\n",
              "         7.8868e-08, 2.1125e-06, 1.8299e-05, 6.5440e-08],\n",
              "        [1.5661e-04, 2.4059e-09, 2.7382e-05, 9.4668e-01, 2.3226e-04, 5.4673e-06,\n",
              "         6.0516e-06, 5.3044e-05, 6.7217e-09, 5.2840e-02],\n",
              "        [1.1040e-04, 1.1350e-09, 1.3539e-06, 6.8617e-02, 3.7689e-05, 9.3123e-01,\n",
              "         1.2341e-08, 4.0611e-08, 1.3595e-08, 2.0269e-09],\n",
              "        [1.3059e-08, 5.8774e-09, 1.9269e-10, 9.9615e-01, 1.1460e-08, 3.2536e-03,\n",
              "         5.9588e-09, 5.8661e-04, 5.8311e-11, 1.4792e-05],\n",
              "        [8.8141e-09, 1.7595e-11, 3.0495e-07, 1.3952e-10, 5.1564e-04, 9.9948e-01,\n",
              "         7.5719e-12, 2.8974e-07, 1.6431e-09, 3.5896e-08],\n",
              "        [2.6859e-04, 2.2885e-10, 7.3531e-05, 9.5515e-01, 2.7795e-06, 4.4462e-02,\n",
              "         2.3374e-06, 4.0987e-06, 3.8968e-05, 1.1022e-07],\n",
              "        [2.2072e-04, 3.5942e-09, 1.4202e-08, 8.7638e-01, 6.1428e-05, 1.2000e-01,\n",
              "         8.4605e-04, 2.4827e-03, 9.4797e-06, 7.1894e-07],\n",
              "        [8.2228e-09, 4.0872e-08, 2.3919e-08, 9.9840e-01, 1.2094e-09, 2.4959e-06,\n",
              "         1.3508e-09, 4.1103e-08, 1.6044e-10, 1.5943e-03],\n",
              "        [4.8157e-04, 2.5616e-07, 2.4199e-01, 1.7088e-02, 6.9221e-01, 1.7779e-03,\n",
              "         1.6979e-06, 1.8765e-06, 3.0615e-10, 4.6454e-02],\n",
              "        [4.7904e-05, 1.7662e-09, 7.6704e-09, 2.2842e-02, 3.6583e-05, 9.4184e-01,\n",
              "         2.8932e-06, 5.8668e-03, 1.0631e-03, 2.8300e-02],\n",
              "        [7.9255e-06, 2.1357e-10, 3.6646e-11, 4.8589e-04, 5.6334e-01, 4.3577e-01,\n",
              "         1.7702e-08, 5.2911e-06, 1.9527e-11, 3.9228e-04],\n",
              "        [2.2278e-09, 5.1214e-19, 4.4919e-07, 9.9935e-01, 9.0253e-07, 6.0159e-04,\n",
              "         1.2671e-10, 1.1535e-06, 3.1262e-11, 4.5369e-05],\n",
              "        [3.2546e-01, 3.4006e-07, 1.6242e-04, 6.8198e-02, 4.4444e-02, 5.6165e-01,\n",
              "         1.2952e-05, 8.5920e-07, 5.6279e-08, 7.2086e-05],\n",
              "        [4.8455e-08, 1.6909e-12, 5.0980e-05, 2.5738e-10, 4.8895e-06, 9.9994e-01,\n",
              "         7.2947e-07, 3.0782e-09, 1.3180e-07, 1.1505e-10],\n",
              "        [7.5372e-03, 2.3524e-11, 9.0751e-07, 2.7300e-01, 1.8972e-04, 8.9680e-06,\n",
              "         3.1239e-03, 7.6601e-06, 4.7036e-08, 7.1613e-01],\n",
              "        [7.8565e-09, 2.5303e-12, 4.3646e-08, 8.3632e-01, 3.7160e-04, 1.0847e-03,\n",
              "         1.9577e-07, 1.6219e-01, 9.6697e-10, 3.1248e-05],\n",
              "        [7.2251e-09, 1.7863e-13, 1.3804e-08, 9.9989e-01, 5.4255e-08, 2.2223e-08,\n",
              "         3.2330e-10, 1.4368e-08, 1.7461e-08, 1.0903e-04],\n",
              "        [1.6974e-05, 3.8291e-08, 5.2685e-05, 3.9221e-06, 1.2112e-01, 8.7693e-01,\n",
              "         1.1656e-04, 4.1774e-04, 5.2163e-10, 1.3362e-03],\n",
              "        [1.7683e-09, 1.4833e-12, 1.1256e-08, 1.2962e-06, 2.1347e-09, 1.0000e+00,\n",
              "         2.3040e-12, 1.7963e-10, 6.6889e-16, 6.3551e-10],\n",
              "        [1.2382e-05, 4.1254e-07, 1.2889e-07, 1.7858e-03, 9.9779e-01, 2.0640e-04,\n",
              "         3.7908e-06, 1.0179e-09, 1.8279e-11, 1.9692e-04],\n",
              "        [1.6752e-09, 2.8607e-09, 2.3687e-07, 1.0977e-06, 1.5385e-05, 9.9958e-01,\n",
              "         1.2038e-06, 3.7141e-07, 1.2044e-11, 4.0663e-04],\n",
              "        [5.4589e-10, 2.6827e-09, 2.1088e-11, 8.8920e-01, 3.6089e-06, 1.1033e-01,\n",
              "         7.2693e-14, 4.5560e-04, 3.0728e-10, 9.9445e-06],\n",
              "        [6.4777e-03, 8.3342e-01, 2.2248e-06, 7.5584e-02, 5.6246e-03, 3.2980e-03,\n",
              "         1.5974e-04, 5.2349e-02, 1.6251e-07, 2.3079e-02],\n",
              "        [2.9512e-06, 7.0923e-06, 1.8175e-08, 9.9980e-01, 1.1558e-05, 1.6635e-04,\n",
              "         7.3967e-10, 1.3831e-05, 1.8019e-06, 2.5655e-07],\n",
              "        [5.7487e-03, 2.4206e-10, 2.9934e-05, 3.1262e-03, 4.6960e-06, 9.9109e-01,\n",
              "         4.6563e-08, 7.5890e-07, 2.5325e-08, 6.4054e-10],\n",
              "        [3.3133e-07, 1.5395e-08, 2.5764e-06, 1.9331e-02, 2.1462e-01, 1.6598e-01,\n",
              "         5.9577e-01, 7.2279e-07, 1.1487e-10, 4.2989e-03],\n",
              "        [2.0806e-02, 1.0939e-08, 7.6655e-09, 5.0703e-01, 3.1612e-01, 1.5602e-01,\n",
              "         1.4602e-05, 6.1810e-09, 3.4086e-06, 3.8340e-06],\n",
              "        [7.5732e-11, 1.1073e-10, 4.3345e-16, 9.7121e-01, 8.3485e-06, 2.8017e-02,\n",
              "         1.4766e-11, 6.5155e-08, 9.3740e-07, 7.6695e-04],\n",
              "        [6.5555e-02, 1.0467e-08, 8.2862e-07, 4.4458e-02, 8.3504e-01, 1.2255e-03,\n",
              "         1.5984e-04, 1.3596e-03, 1.2240e-11, 5.2207e-02],\n",
              "        [8.7096e-06, 5.4071e-06, 6.9440e-05, 8.4116e-05, 8.3422e-07, 9.9537e-01,\n",
              "         4.4450e-09, 2.5064e-05, 9.3560e-11, 4.4382e-03],\n",
              "        [5.6943e-08, 9.9694e-08, 1.3296e-05, 7.7858e-05, 1.3333e-01, 8.5325e-01,\n",
              "         1.5620e-05, 1.0189e-02, 1.9950e-07, 3.1331e-03],\n",
              "        [3.1037e-04, 2.6757e-11, 3.0055e-04, 9.8667e-01, 2.1841e-06, 1.2583e-02,\n",
              "         2.0884e-12, 8.9302e-05, 2.7684e-10, 4.2685e-05],\n",
              "        [5.4555e-08, 9.1109e-11, 3.6614e-07, 8.6818e-03, 2.9079e-04, 9.9101e-01,\n",
              "         1.3759e-05, 1.1255e-08, 8.4320e-14, 8.3618e-08],\n",
              "        [4.3324e-05, 1.2895e-10, 3.1629e-06, 8.7119e-01, 5.5951e-02, 7.2648e-02,\n",
              "         9.5377e-05, 3.7703e-07, 2.1339e-09, 7.0669e-05],\n",
              "        [1.0706e-02, 3.9306e-04, 3.2502e-05, 3.8769e-03, 9.7575e-01, 8.9449e-03,\n",
              "         7.0559e-05, 1.2607e-04, 1.9721e-07, 9.6386e-05],\n",
              "        [6.0527e-07, 2.9046e-06, 8.2619e-07, 1.5220e-02, 6.3791e-03, 9.7832e-01,\n",
              "         2.0043e-09, 6.8385e-05, 7.1405e-10, 9.1859e-06],\n",
              "        [6.5038e-03, 2.8222e-15, 2.7704e-07, 9.9307e-01, 2.5831e-06, 1.1558e-05,\n",
              "         1.5688e-10, 1.6832e-07, 3.0219e-08, 4.1179e-04]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building network for image number recognition"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Hidden layer with sigmoid activation\n",
        "        x = F.sigmoid(self.hidden(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the network and look at it's text representation\n",
        "model = Network()\n",
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden1 = nn.Linear(784, 128)\n",
        "        # Second hidden\n",
        "        self.hidden2 = nn.Linear(128, 64)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # 1 hidden layer with relu activation\n",
        "        x = F.relu(self.hidden1(x))\n",
        "        # 2 hidden layer with relu activation\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network1()\n",
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": [
              "Network1(\n",
              "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.hidden1.weight)\n",
        "print(model.hidden1.bias)\n",
        "print(model.hidden2.weight)\n",
        "print(model.hidden2.bias)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0340,  0.0067,  0.0152,  ...,  0.0171, -0.0345,  0.0263],\n",
            "        [ 0.0049, -0.0070,  0.0175,  ..., -0.0035, -0.0112,  0.0164],\n",
            "        [ 0.0284,  0.0210, -0.0287,  ...,  0.0231, -0.0279, -0.0132],\n",
            "        ...,\n",
            "        [-0.0257, -0.0091, -0.0303,  ...,  0.0010,  0.0221,  0.0105],\n",
            "        [ 0.0015, -0.0126,  0.0071,  ...,  0.0034,  0.0136,  0.0090],\n",
            "        [-0.0145, -0.0175,  0.0015,  ...,  0.0006, -0.0315,  0.0100]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0288,  0.0176,  0.0343,  0.0254, -0.0033,  0.0076, -0.0077, -0.0086,\n",
            "         0.0209, -0.0210,  0.0286,  0.0117, -0.0188,  0.0013, -0.0105, -0.0211,\n",
            "         0.0009,  0.0022, -0.0245,  0.0222, -0.0050, -0.0263, -0.0247, -0.0289,\n",
            "         0.0260,  0.0025,  0.0036, -0.0316,  0.0287, -0.0115,  0.0257,  0.0206,\n",
            "        -0.0044, -0.0181,  0.0273,  0.0284,  0.0059, -0.0242, -0.0130,  0.0023,\n",
            "         0.0158,  0.0281,  0.0183,  0.0060, -0.0267, -0.0293, -0.0307, -0.0172,\n",
            "         0.0064, -0.0238, -0.0104,  0.0190, -0.0297, -0.0215, -0.0191,  0.0142,\n",
            "         0.0049,  0.0286, -0.0052,  0.0046,  0.0253,  0.0225,  0.0188,  0.0005,\n",
            "        -0.0252, -0.0042,  0.0295, -0.0283, -0.0333,  0.0196, -0.0281,  0.0223,\n",
            "         0.0329,  0.0058,  0.0244,  0.0130,  0.0038,  0.0047,  0.0020,  0.0302,\n",
            "         0.0182, -0.0134,  0.0036,  0.0315, -0.0340, -0.0346,  0.0246,  0.0296,\n",
            "        -0.0021,  0.0301,  0.0338,  0.0003,  0.0208,  0.0350, -0.0291,  0.0016,\n",
            "         0.0065, -0.0238, -0.0083,  0.0045, -0.0121, -0.0104, -0.0239,  0.0228,\n",
            "         0.0021, -0.0336,  0.0254,  0.0275, -0.0273,  0.0073,  0.0004, -0.0095,\n",
            "         0.0314,  0.0211,  0.0284, -0.0144, -0.0076, -0.0104,  0.0177,  0.0251,\n",
            "         0.0056,  0.0004, -0.0256, -0.0050, -0.0036,  0.0326,  0.0130,  0.0137],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0677, -0.0307, -0.0205,  ...,  0.0868, -0.0668, -0.0774],\n",
            "        [ 0.0413,  0.0588,  0.0772,  ..., -0.0396, -0.0205, -0.0797],\n",
            "        [ 0.0559, -0.0501,  0.0277,  ...,  0.0473, -0.0185,  0.0750],\n",
            "        ...,\n",
            "        [-0.0262,  0.0394, -0.0094,  ...,  0.0335, -0.0394, -0.0279],\n",
            "        [ 0.0347, -0.0678, -0.0651,  ...,  0.0144,  0.0839,  0.0676],\n",
            "        [-0.0805, -0.0808, -0.0846,  ...,  0.0202,  0.0649, -0.0068]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0168, -0.0297,  0.0318, -0.0178, -0.0335, -0.0776,  0.0004,  0.0551,\n",
            "         0.0707, -0.0502, -0.0724, -0.0398, -0.0670,  0.0694,  0.0868,  0.0170,\n",
            "        -0.0552,  0.0351,  0.0736, -0.0607,  0.0173, -0.0217, -0.0049,  0.0189,\n",
            "        -0.0778, -0.0867,  0.0482,  0.0115,  0.0020,  0.0744,  0.0649, -0.0144,\n",
            "         0.0246,  0.0369, -0.0568, -0.0477, -0.0221,  0.0095,  0.0354,  0.0832,\n",
            "        -0.0417, -0.0356,  0.0803, -0.0278,  0.0632,  0.0025, -0.0577, -0.0813,\n",
            "         0.0107, -0.0304, -0.0063, -0.0579, -0.0220, -0.0059,  0.0553, -0.0583,\n",
            "         0.0463,  0.0006,  0.0730,  0.0031, -0.0498, -0.0039,  0.0029, -0.0315],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "execution_count": 23,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define network architecture using wrapper\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "print(model)\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get the data\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass\n",
        "logits = model(images)\n",
        "\n",
        "# Calculate the loss\n",
        "loss = criterion(logits, labels)\n",
        "\nprint(loss)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "tensor(2.3251, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Architecture "
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "# Define the loss and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        \n",
        "        # Gradient to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model.forward(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss / len(trainloader)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.871655824214919\n",
            "Training loss: 0.8313357959360456\n",
            "Training loss: 0.5254041539199317\n",
            "Training loss: 0.4294451842112328\n",
            "Training loss: 0.3840954667850852\n",
            "Training loss: 0.35701972975342006\n",
            "Training loss: 0.3382105703261107\n",
            "Training loss: 0.32385340271823443\n",
            "Training loss: 0.31170686775210826\n",
            "Training loss: 0.3015429663108483\n",
            "Training loss: 0.2928286786955684\n",
            "Training loss: 0.2848892825355789\n",
            "Training loss: 0.27795449352022933\n",
            "Training loss: 0.2711571081360774\n",
            "Training loss: 0.2644727985932629\n",
            "Training loss: 0.2586706522971328\n",
            "Training loss: 0.25259071639351754\n",
            "Training loss: 0.24689979888578215\n",
            "Training loss: 0.2411695709352745\n",
            "Training loss: 0.23581177971240427\n"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "logps = model.forward(img)\n",
        "\n",
        "ps = torch.exp(logps)\n",
        "halper.view_classify(img.view(1, 28, 28), ps)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ],
            "image/png": [
              "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\n"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 423,
              "height": 226
            }
          }
        }
      ],
      "execution_count": 29,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}